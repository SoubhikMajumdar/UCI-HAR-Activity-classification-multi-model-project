# -*- coding: utf-8 -*-
"""257_HAR_classification_v4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18r4K-fV_HxngfYAtSZjTXRURlM9BJWND

##### Katherine Sarna (014908387) and Soubhik Majumdar (018175885)
##### Dr. Birsen Sirkeci, EE 257: Machine Learning Project
##### Code
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
# %matplotlib inline
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# Code and Analysis for this cell created by: Soubhik Majumdar

# Load feature names
features = pd.read_csv("/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/features.txt", sep="\s+", header=None, names=["index", "feature"])
feature_names = features["feature"].tolist()

# Deduplicate feature names
def make_unique(names):
    seen = {}
    unique_names = []
    for name in names:
        if name not in seen:
            seen[name] = 0
            unique_names.append(name)
        else:
            seen[name] += 1
            unique_names.append(f"{name}_{seen[name]}")
    return unique_names

unique_feature_names = make_unique(feature_names)

# Load the dataset
X_train = pd.read_csv("/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/train/X_train.txt", sep="\s+", header=None, names=unique_feature_names)
y_train = pd.read_csv("/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/train/y_train.txt", header=None, names=["Activity"])
subject_train = pd.read_csv("/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/train/subject_train.txt", header=None, names=["Subject"])

# Combine
train_df = pd.concat([subject_train, y_train, X_train], axis=1)
train_df.to_csv('/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/X_y_concat.csv')
# Display
train_df.head()

"""#### Dataset observation
As some of the features are duplicated, we find them and make them unique so as to avoid repetition. We combine subject IDs, activity labels, and features into a single DataFrame called train_df. The activity column in the dataframe is the dependent variable. There are 561 independent variables (predictors) in the dataset.    
"""

# Remove outliers using IQR method on feature columns only
Q1 = train_df.iloc[:, 2:].quantile(0.25)
Q3 = train_df.iloc[:, 2:].quantile(0.75)
IQR = Q3 - Q1

# Create a boolean mask for rows that are within 1.5 * IQR for all feature columns
mask = ~((train_df.iloc[:, 2:] < (Q1 - 1.5 * IQR)) | (train_df.iloc[:, 2:] > (Q3 + 1.5 * IQR))).any(axis=1)

# Apply the mask to remove outliers
train_df_cleaned = train_df[mask].reset_index(drop=True)
train_df_cleaned.describe()

"""#### Outlier removal
No outliers detected so we can use train_df going forward
"""

# Loading the activity labels
activity_labels = pd.read_csv('/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/activity_labels.txt', sep='\s+', header=None, names=['ActivityID', 'Activity'])

print(activity_labels)

"""#### Activity labels

Each Activity is mapped to a ActivityID (int64 datatype) as shown above
"""

train_df.info()

"""The predictors (561 predictors) datatypes are all float64"""

train_df.head()

train_df.describe()

df = train_df.dropna() #drop rows with NA values
df.describe()

# Code and analysis for this cell created by: Soubhik Majumdar

# Map activity IDs to names
activity_map = dict(zip(activity_labels.ActivityID, activity_labels.Activity))
train_df['ActivityName'] = train_df['Activity'].map(activity_map)

# Compute value counts and percentages
activity_counts = train_df["ActivityName"].value_counts()
activity_percentages = 100 * activity_counts / activity_counts.sum()

# Plot
plt.figure(figsize=(10, 6))
bars = plt.bar(activity_counts.index, activity_counts.values, color='gray')
plt.title("Activity Distribution in Training Set")
plt.xlabel("Activity")
plt.ylabel("Number of Samples")
plt.xticks(rotation=45)

# Add percentage labels on top of bars
for bar, percentage in zip(bars, activity_percentages):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 5, f'{percentage:.1f}%',
             ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

"""##### Analysis: Katherine Sarna
### PCA Scatter Plot of Human Activity Recognition Data

This visualization applies Principal Component Analysis (PCA) to the standardized training data (`X_train`) from the UCI HAR dataset, reducing it to two dimensions for plotting. Each point in the scatter plot represents a sample, colored by its corresponding activity label. This helps reveal clustering patterns and separability between different human activities.

"""

# Code for this cell created by: Katherine Sarna

# SCATTER PLOT
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# load y_train as a SERIES, not as a dataframe column so we can use []
y_train = pd.read_csv('/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/train/y_train.txt', delim_whitespace=True, header=None)[0]

# load activity labels (index = ID, column = label)
activity_labels = pd.read_csv(
    '/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/activity_labels.txt',
    delim_whitespace=True,
    header=None,
    index_col=0
)

# Convert activity_labels to a dictionary
label_map = activity_labels[1].to_dict()

# Map activity numbers to names
y_train = y_train.map(label_map)

# standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

# apply PCA to reduce to 2 dimensions
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
# plot PCA scatter plot
plt.figure(figsize=(10, 6))
for activity in y_train.unique():
    idx = y_train == activity
    plt.scatter(X_pca[idx, 0], X_pca[idx, 1], label=activity, alpha=0.6)

plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA of Human Activity Recognition Dataset')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Code and analysis for this cell created by: Soubhik Majumdar

import plotly.express as px
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Load data and prepare same as before...
X = pd.read_csv("/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/train/X_train.txt", delim_whitespace=True, header=None)
y = pd.read_csv("/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/train/y_train.txt", delim_whitespace=True, header=None, names=["ActivityID"])
activity_labels = pd.read_csv("/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/activity_labels.txt", sep='\s+', header=None, names=['ActivityID', 'Activity'])
activity_map = dict(zip(activity_labels.ActivityID, activity_labels.Activity))
y["ActivityName"] = y["ActivityID"].map(activity_map)

# PCA
X_scaled = StandardScaler().fit_transform(X)
X_pca = PCA(n_components=3).fit_transform(X_scaled)

# Build DataFrame for plotting
pca_df = pd.DataFrame(X_pca, columns=["PC1", "PC2", "PC3"])
pca_df["Activity"] = y["ActivityName"]

# Plot with Plotly
fig = px.scatter_3d(pca_df, x="PC1", y="PC2", z="PC3", color="Activity",
                    title="3D PCA of Human Activity Recognition Dataset",
                    opacity=0.6)

fig.show()

"""#### Principal Component Analysis

Performing Principal Component Analysis (PCA) to visualize the high-dimensional Human Activity Recognition (HAR) dataset in a reduced 3D space. It applies PCA to reduce the 561-dimensional feature space to just 3 principal components: the directions of maximum variance in the data. This is important for dataset description because it allows us to visually assess how separable different activities are based on the extracted features. Clear clustering in the plot suggests that the model can distinguish between activities, validating the quality and structure of the data.

##### Analysis: Katherine Sarna
### Correlation Matrix of UCI HAR Features

This heatmap visualizes the correlation matrix of the 561 features in the UCI HAR training dataset (`X_train`). By computing pairwise correlations between features, we can identify potential redundancy or strong relationships within the data, which can inform feature selection or dimensionality reduction techniques like PCA.
"""

# Code for this cell created by: Katherine Sarna

# CORRELATION MATRIX
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

X_train = pd.read_csv('/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/train/X_train.txt', delim_whitespace=True, header=None)

# Load feature names
feature_names = pd.read_csv('/content/gdrive/MyDrive/ML Project/UCI HAR Dataset/features.txt', delim_whitespace=True, header=None, usecols=[1])
X_train.columns = feature_names[1]

# Compute the correlation matrix (this may be large: 561 x 561)
correlation_matrix = X_train.corr()

# Plot a heatmap of the correlation matrix
plt.figure(figsize=(14, 12))
sns.heatmap(correlation_matrix, cmap='coolwarm', xticklabels=False, yticklabels=False)
plt.title('Correlation Matrix of Features (UCI HAR Dataset)', fontsize=16)
plt.tight_layout()
plt.show()
correlation_matrix = df.corr()

"""d. data cleaning"""

from sklearn.decomposition import PCA

# pca = PCA(n_components = 'mle')

pca = PCA(n_components=0.95) # NEW - optimization part (h)
X_pca = pca.fit_transform(X_train)

# Prepare data
X = X_pca
y = train_df["Activity"]
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "LDA": LinearDiscriminantAnalysis(),
    "QDA": QuadraticDiscriminantAnalysis(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier()
}

# Train and evaluate
from sklearn.metrics import accuracy_score, classification_report

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    print(f"\n{name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

"""### (h) Optimization

The outcome of the models is mostly good, but we could try for a higher accuracy and/or F1 score with the KNN model. Precision is also consistently the lowest metric in the 7 models' results, so we can employ techniques to improve it.
"""

# takes a long time

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_scaled, y_train)

best_rf = grid_search.best_estimator_
y_pred = best_rf.predict(X_test_scaled)
print("Best Random Forest Accuracy:", accuracy_score(y_test, y_pred))

# repeat this for other models like SVM (try different kernels and C values), KNN (n_neighbors, weights), etc.

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# Define hyperparameter grids
param_grids = {
    "Logistic Regression": {
        "model": LogisticRegression(max_iter=1000),
        "params": {
            "C": [0.1, 1, 10],
            "solver": ["liblinear", "lbfgs"]
        }
    },
    "LDA": {
        "model": LinearDiscriminantAnalysis(),
        "params": {
            "solver": ["svd", "lsqr"]
        }
    },
    "QDA": {
        "model": QuadraticDiscriminantAnalysis(),
        "params": {
            "reg_param": [0.0, 0.01, 0.1]
        }
    },
    "KNN": {
        "model": KNeighborsClassifier(),
        "params": {
            "n_neighbors": [3, 5, 7],
            "weights": ["uniform", "distance"]
        }
    },
    "SVM": {
        "model": SVC(),
        "params": {
            "C": [0.1, 1, 10],
            "kernel": ["linear", "rbf"],
            "gamma": ["scale", "auto"]
        }
    },
    "Decision Tree": {
        "model": DecisionTreeClassifier(),
        "params": {
            "max_depth": [None, 10, 20],
            "min_samples_split": [2, 5]
        }
    },
    "Random Forest": {
        "model": RandomForestClassifier(),
        "params": {
            "n_estimators": [100, 200],
            "max_depth": [None, 10, 20],
            "min_samples_split": [2, 5]
        }
    }
}

# Iterate and tune each model
best_models = {}
accuracies = {}

for name, mp in param_grids.items():
    print(f"\nTuning {name}...")
    grid = GridSearchCV(mp["model"], mp["params"], cv=5, scoring='accuracy', n_jobs=-1)
    grid.fit(X_train_scaled, y_train)

    best_model = grid.best_estimator_
    best_models[name] = best_model

    y_pred = best_model.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    accuracies[name] = acc

    print(f"Best Params for {name}: {grid.best_params_}")
    print(f"{name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

# Plot bar graph of model accuracies
plt.figure(figsize=(10, 6))
bars = plt.bar(accuracies.keys(), accuracies.values())
plt.ylabel("Accuracy")
plt.xlabel("Model")
plt.title("Model Accuracies on Test Set")
plt.xticks(rotation=45)

# Add accuracy values on top of bars
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f"{yval:.2f}", ha='center', va='bottom')

plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_estimator(model, X_test_scaled, y_test, cmap='Blues')
plt.title(f"Confusion Matrix - {name}")
plt.show()

# confusion matrices for ALL 6 models
disp = ConfusionMatrixDisplay.from_estimator(best_model, X_test_scaled, y_test, cmap='Blues', xticks_rotation=45)
disp.ax_.set_title(f"Confusion Matrix - {name}")
plt.tight_layout()
plt.show()

# POTENTIALLY use in place of train_test_split
# to use CV / k-fold cross validation instead of split, might be more reliable in estimating

# from sklearn.model_selection import cross_val_score

# for name, model in models.items():
#     scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
#     print(f"{name} CV Accuracy: {scores.mean():.4f} Â± {scores.std():.4f}")

# Cleaner eval function (optinoal to use or not)

def evaluate_model(model, name, X_train, X_test, y_train, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\n{name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))



